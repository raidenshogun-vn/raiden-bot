const path = require('path');
const fs = require('fs');
require('dotenv').config();
const { GoogleGenerativeAI } = require('@google/generative-ai');
const { QuotaLog } = require('../models/QuotaLog');
const character = require('../config/character');
const { loadLanguages } = require('../helpers/getLang');
const winston = require('winston');
const pLimit = require('p-limit').default;
const languages = loadLanguages();

// Logger config
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  transports: [new winston.transports.Console({ format: winston.format.simple() })]
});

// ===== Configuration =====
const FREE_MODELS = [
  'gemini-2.0-flash',
  'gemini-2.0-flash-lite',
  'gemini-2.5-flash-lite-preview-06-17',
  'gemini-2.5-flash'
];
const RETRY_OPTIONS = {
  attempts: 3,
  minDelayMs: 500,
  maxDelayMs: 2000
};

const CONCURRENCY_LIMIT = 10;
const limit = pLimit(CONCURRENCY_LIMIT);

// ===== Load API Keys =====
const GEMINI_API_KEYS = Object.entries(process.env)
  .filter(([k]) => k.startsWith('AUTO_'))
  .map(([, v]) => v)
  .filter(Boolean);

if (!GEMINI_API_KEYS.length) {
  throw new Error('‚ö†Ô∏è Kh√¥ng c√≥ API key n√†o.');
}

// ===== API Key Manager (Round-robin) =====
class ApiKeyManager {
  constructor(keys) {
    this.pool = keys.map(k => ({ key: k, cooldownUntil: 0 }));
    this.index = 0;
  }

  getNextKey() {
    const now = Date.now();
    const n = this.pool.length;

    for (let i = 0; i < n; i++) {
      const idx = (this.index + i) % n;
      const entry = this.pool[idx];
      if (entry.cooldownUntil <= now) {
        this.index = (idx + 1) % n;
        return entry;
      }
    }

    return null;
  }

  setCooldown(entry, seconds) {
    entry.cooldownUntil = Date.now() + seconds * 1000;
  }
}

const apiKeyManager = new ApiKeyManager(GEMINI_API_KEYS);

// ===== Model Cache =====
const modelCache = new Map();

function getCachedModel(apiKey, modelId, maxTokens, customTemp) {
  const cacheKey = `${apiKey}::${modelId}::${maxTokens}::${customTemp ?? 'default'}`;
  if (modelCache.has(cacheKey)) return modelCache.get(cacheKey);

  const genAI = new GoogleGenerativeAI(apiKey);
  const model = genAI.getGenerativeModel({
    model: modelId,
    generationConfig: {
      maxOutputTokens: maxTokens,
      ...(customTemp !== undefined && { temperature: customTemp })
    }
  });

  // console.log(`üì° [Model Init] model=${modelId}, key=...${apiKey.slice(-4)}, temperature=${customTemp ?? 'default'}`);
  modelCache.set(cacheKey, model);
  return model;
}

// ===== Retry with backoff =====
async function retryWithBackoff(fn, options = RETRY_OPTIONS) {
  const { attempts, minDelayMs, maxDelayMs } = options;
  for (let i = 0; i < attempts; i++) {
    try {
      return await fn();
    } catch (err) {
      if (i === attempts - 1) throw err;
      const delay = Math.min(minDelayMs * 2 ** i, maxDelayMs);
      const jitter = Math.random() * delay * 0.3;
      const wait = delay + jitter;
      logger.warn(`‚è≥ Retry #${i + 1} in ${Math.round(wait)}ms`);
      await new Promise(r => setTimeout(r, wait));
    }
  }
}

// ===== Core logic (SECURE version) =====
async function generateResponseInternal(
  prompt,
  systemPrompt,
  language = 'vn',
  userId = null,
  username = null,
  displayName = null,
  overrideMaxTokens = null
) {
  const langObj = languages[language] || languages.vn;
  const note ='IMPORTANT: You MUST respond only in the correct language.';

  // Get maxTokens
const maxTokens = overrideMaxTokens || 2000;
  // Get user temperature setting
const customTemp = 1;

  for (const modelId of FREE_MODELS) {
    let attemptsPerModel = 0;
    while (attemptsPerModel < apiKeyManager.pool.length) {
      const keyEntry = apiKeyManager.getNextKey();
      if (!keyEntry) {
        throw new Error('üö´ T·∫•t c·∫£ API key ƒë·ªÅu ƒëang cooldown. Vui l√≤ng th·ª≠ l·∫°i sau.');
      }

      try {
        const model = getCachedModel(keyEntry.key, modelId, maxTokens, customTemp);

        // const finalPrompt = {
        //   systemInstruction: {
        //     role: 'system',
        //     parts: [{ text: systemPrompt }]
        //   },
        //   contents: [
        //     {
        //       role: 'user',
        //       parts: [{ text: `${note}\n${displayName}: ${prompt}\n${character.displayName}:` }]
        //     }
        //   ]
        // };

        // logger.info('üì§ Gemini Prompt Sent:');
        // logger.info(JSON.stringify(finalPrompt, null, 2));

        const response = await retryWithBackoff(() =>
          model.generateContent({
            systemInstruction: {
              role: 'system',
              parts: [{ text: systemPrompt }]
            },
            contents: [
              {
                role: 'user',
                parts: [{ text: `${note}\n\nUser: ${prompt}` }]
              }
            ]
          })
        );

        let text = response.response.text();

        // L·ªçc emoji (Unicode)
        text = text.replace(/[\p{Emoji_Presentation}\p{Extended_Pictographic}]/gu, '');
        // L·ªçc promptContext kh·ªèi c√¢u tr·∫£ l·ªùi
          const contextLines = [
            langObj?.promptContext?.header,
            ...(langObj?.promptContext?.instructions || []),
            langObj?.promptContext?.historyHeader
          ].filter(Boolean);

          for (const line of contextLines) {
            if (!line) continue;
            const escapedLine = line.replace(/[.*+?^${}()|[\]\\]/g, '\\$&');
            const regex = new RegExp(`^\\s*${escapedLine}\\s*$`, 'gm');
            text = text.replace(regex, '');
          }

          text = text.replace(/^\s*\n/gm, '').trim();
          
          const nameRegex = new RegExp(`^\\s*(Character|${character.displayName}|[\\w√Ä-·ª∏√†-·ªπ]+):\\s*`, 'gm');
          text = text.replace(nameRegex, '');

           
               // ===== [M·ªöI] B·ªò L·ªåC REGEX N√ÇNG CAO (X·ª≠ l√Ω Stuttering) =====
        // Chi·∫øn l∆∞·ª£c: B·∫£o v·ªá -> Thanh tr·ª´ng -> Kh√¥i ph·ª•c.

        // B∆Ø·ªöC 1: B·∫¢O V·ªÜ c√°c tr∆∞·ªùng h·ª£p "l·∫Øp b·∫Øp" h·ª£p l·ªá (v√≠ d·ª•: "em... em").
        // Ta t√¨m c√°c m·∫´u "word...word" (kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng) v√† thay th·∫ø d·∫•u "..."
        // b·∫±ng m·ªôt placeholder ƒë·∫∑c bi·ªát ƒë·ªÉ ch√∫ng kh√¥ng b·ªã x√≥a ·ªü b∆∞·ªõc sau.
        const STUTTER_PLACEHOLDER = '___STUTTER___';
        // Regex gi·∫£i th√≠ch:
        // (\w+): B·∫Øt l·∫•y m·ªôt t·ª´ (group 1).
        // \s*\.{3,}\s*: D·∫•u ba ch·∫•m v√† c√°c kho·∫£ng tr·∫Øng xung quanh.
        // \1: Backreference, ƒë·∫£m b·∫£o t·ª´ ti·∫øp theo ph·∫£i GI·ªêNG H·ªÜT t·ª´ trong group 1.
        // /gi: g = global (to√†n b·ªô vƒÉn b·∫£n), i = case-insensitive (kh√¥ng ph√¢n bi·ªát hoa th∆∞·ªùng).
        text = text.replace(/(\w+)\s*\.{3,}\s*(\1)/gi, `$1${STUTTER_PLACEHOLDER}$2`);

        // B∆Ø·ªöC 2: THANH TR·ª™NG t·∫•t c·∫£ c√°c d·∫•u "..." c√≤n l·∫°i (l·ªói l·∫°m d·ª•ng).
        // V√¨ c√°c tr∆∞·ªùng h·ª£p h·ª£p l·ªá ƒë√£ ƒë∆∞·ª£c b·∫£o v·ªá, gi·ªù ta c√≥ th·ªÉ x√≥a ph·∫ßn c√≤n l·∫°i m·ªôt c√°ch an to√†n.
        // Bi·∫øn "t·ª´... t·ª´ kh√°c" th√†nh "t·ª´ t·ª´ kh√°c".
        text = text.replace(/\s*\.{3,}\s*/g, ' ');
        // Bi·∫øn "c√¢u..." ·ªü cu·ªëi th√†nh "c√¢u."
        text = text.replace(/(?<=\w)\s*\.{3,}/g, '.');

        // B∆Ø·ªöC 3: KH√îI PH·ª§C c√°c tr∆∞·ªùng h·ª£p "l·∫Øp b·∫Øp" ƒë√£ ƒë∆∞·ª£c b·∫£o v·ªá.
        // ƒê·ªïi placeholder tr·ªü l·∫°i th√†nh d·∫•u "..." chu·∫©n.
        text = text.replace(new RegExp(STUTTER_PLACEHOLDER, 'g'), '... ');

        // B∆Ø·ªöC 4: D·ªçn d·∫πp cu·ªëi c√πng sau t·∫•t c·∫£ c√°c b∆∞·ªõc thay th·∫ø.
        // Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a tr∆∞·ªõc d·∫•u c√¢u.
        text = text.replace(/\s+([.,;?!])/g, '$1');
        // ƒê·∫£m b·∫£o ch·ªâ c√≥ m·ªôt kho·∫£ng tr·∫Øng gi·ªØa c√°c t·ª´.
        text = text.replace(/\s+/g, ' ');
        // L·ªçc prompt leak (optional nh∆∞ng khuy·∫øn kh√≠ch)
        const promptLeakPatterns = [
          /remember:/i,
          /you are the main character/i,
          /never reveal/i,
          /stick to your assigned role/i,
          /system prompt/i
        ];
        if (promptLeakPatterns.some(rx => rx.test(text))) {
          throw new Error('üõë Gemini response leaked internal prompt!');
        }

        logger.info(`‚úÖ Success: model=${modelId}, key=...${keyEntry.key.slice(-4)}`);

        if (userId && username) {
          await QuotaLog.create({ userId, username, model: modelId, timestamp: new Date() });
        }

        return text;
      } catch (err) {
        const msg = err.message || '';
        if (msg.includes('429')) {
          const match = msg.match(/"retryDelay":"(\d+)s"/);
          const sec = match ? parseInt(match[1], 10) : 30;
          apiKeyManager.setCooldown(keyEntry, sec);
          logger.warn(`‚ö†Ô∏è Key ...${keyEntry.key.slice(-4)} cooldown ${sec}s`);
          attemptsPerModel++;
          continue;
        }

        logger.error(`‚ùå Error: model=${modelId}, key=...${keyEntry.key.slice(-4)}, error=${msg}`);
        break;
      }
    }

    logger.warn(`‚ö†Ô∏è Model ${modelId} failed on all keys. Trying next model.`);
  }

  throw new Error('‚ùå T·∫•t c·∫£ model free ƒë·ªÅu h·∫øt quota ho·∫∑c l·ªói.');
}


// ===== Export v·ªõi gi·ªõi h·∫°n ƒë·ªìng th·ªùi =====
module.exports = {
  generateResponse: (...args) =>
    limit(() => {
      if (limit.pendingCount > 5) {
        logger.warn(`üö¶ ƒêang c√≥ ${limit.pendingCount} request ch·ªù x·ª≠ l√Ω...`);
      }
      return generateResponseInternal(...args);
    })
};
